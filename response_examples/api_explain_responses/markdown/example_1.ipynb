{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TtKZfz1PKE4S",
        "PCgj_DL5LD1u"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Explaining a function without API context"
      ],
      "metadata": {
        "id": "TtKZfz1PKE4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the GPTService using 'api_explain' as the role context\n",
        "# The markdown table format is set to 'pipes' which is the format\n",
        "# necessary to render tables in Jupyter style notebooks\n",
        "# The parameter 'prompt_context; is set to false, since in this case\n",
        "# we are not providing any API documention, only the desired function\n",
        "pandas_api = gpt.GPTService(role_context='api_explain',\n",
        "                            temperature=0,\n",
        "                            prompt_context=False,\n",
        "                            md_table_format_style='pipes')"
      ],
      "metadata": {
        "id": "mcINnF1bFzsb",
        "outputId": "e5a524fb-8bc4-4cf6-90cb-6c58195c6bc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-fdaa7244a7a9>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# The parameter 'prompt_context; is set to false, since in this case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# we are not providing any API documention, only the desired function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m pandas_api = gpt.GPTService(role_context='api_explain',\n\u001b[0m\u001b[1;32m      7\u001b[0m                             \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                             \u001b[0mprompt_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gpt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Send the function/class/method to be explained\n",
        "pandas_api.prompt = \"pandas .pivot function\""
      ],
      "metadata": {
        "id": "5xj9oCLjGCAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass the prompt to OpenAI\n",
        "pandas_api.get_response(pandas_api.prompt)"
      ],
      "metadata": {
        "id": "jp_pZ6OBGN4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following is result is returned in plain text, with proper markdown formatting, which can be copied and pasted into a new markdown cell. Below is the final result."
      ],
      "metadata": {
        "id": "hL7gN52jKwcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pandas .pivot function\n",
        "\n",
        "The `pivot` function in the pandas library allows you to reshape and transform your data by converting rows into columns. It is a powerful tool for data manipulation and analysis.\n",
        "\n",
        "## Description\n",
        "\n",
        "The `pivot` function takes a DataFrame as input and returns a new DataFrame with reshaped data. It allows you to specify the index, columns, and values to use for the new DataFrame.\n",
        "\n",
        "## Parameters\n",
        "\n",
        "The `pivot` function has the following parameters:\n",
        "\n",
        "| Parameter | Description |\n",
        "| --- | --- |\n",
        "| index | Column(s) to use as the index for the new DataFrame. |\n",
        "| columns | Column(s) to use as the columns for the new DataFrame. |\n",
        "| values | Column(s) to use as the values for the new DataFrame. |\n",
        "| aggfunc | Function to use for aggregating duplicate values. Default is None. |\n",
        "| fill_value | Value to replace missing values with. Default is None. |\n",
        "\n",
        "## Attributes\n",
        "\n",
        "The `pivot` function does not have any specific attributes.\n",
        "\n",
        "## Returns\n",
        "\n",
        "The `pivot` function returns a new DataFrame with reshaped data.\n",
        "\n",
        "## Code Examples\n",
        "\n",
        "Here are three examples demonstrating the usage of the `pivot` function:\n",
        "\n",
        "### Example 1\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {'Name': ['John', 'Jane', 'Mike', 'Emily'],\n",
        "        'City': ['New York', 'London', 'Paris', 'Tokyo'],\n",
        "        'Salary': [5000, 6000, 4500, 5500]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Pivot the DataFrame\n",
        "pivot_df = df.pivot(index='Name', columns='City', values='Salary')\n",
        "\n",
        "print(pivot_df)\n",
        "```\n",
        "\n",
        "Output:\n",
        "```\n",
        "City   London  New York  Paris  Tokyo\n",
        "Name                                \n",
        "Emily     NaN       NaN    NaN   5500\n",
        "Jane    6000       NaN    NaN    NaN\n",
        "John     NaN      5000    NaN    NaN\n",
        "Mike     NaN       NaN   4500    NaN\n",
        "```\n",
        "\n",
        "### Example 2\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {'Name': ['John', 'Jane', 'Mike', 'Emily'],\n",
        "        'City': ['New York', 'London', 'Paris', 'Tokyo'],\n",
        "        'Salary': [5000, 6000, 4500, 5500],\n",
        "        'Age': [30, 25, 35, 28]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Pivot the DataFrame\n",
        "pivot_df = df.pivot(index='Name', columns='City', values=['Salary', 'Age'])\n",
        "\n",
        "print(pivot_df)\n",
        "```\n",
        "\n",
        "Output:\n",
        "```\n",
        "        Salary                       Age                  \n",
        "City    London New York Paris Tokyo London New York Paris Tokyo\n",
        "Name                                                          \n",
        "Emily      NaN      NaN   NaN  5500    NaN      NaN   NaN    28\n",
        "Jane     6000      NaN   NaN   NaN     25      NaN   NaN   NaN\n",
        "John      NaN     5000   NaN   NaN    NaN       30   NaN   NaN\n",
        "Mike      NaN      NaN  4500   NaN    NaN      NaN    35   NaN\n",
        "```\n",
        "\n",
        "### Example 3\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {'Name': ['John', 'Jane', 'Mike', 'Emily'],\n",
        "        'City': ['New York', 'London', 'Paris', 'Tokyo'],\n",
        "        'Salary': [5000, 6000, 4500, 5500],\n",
        "        'Age': [30, 25, 35, 28],\n",
        "        'Department': ['Sales', 'Marketing', 'Sales', 'HR']}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Pivot the DataFrame\n",
        "pivot_df = df.pivot(index=['Department', 'Name'], columns='City', values=['Salary', 'Age'])\n",
        "\n",
        "print(pivot_df)\n",
        "```\n",
        "\n",
        "Output:\n",
        "```\n",
        "                   Salary                       Age                  \n",
        "City               London New York Paris Tokyo London New York Paris Tokyo\n",
        "Department Name                                                          \n",
        "HR         Emily      NaN      NaN   NaN  5500    NaN      NaN   NaN    28\n",
        "Marketing  Jane     6000      NaN   NaN   NaN     25      NaN   NaN   NaN\n",
        "Sales      John      NaN     5000   NaN   NaN    NaN       30   NaN   NaN\n",
        "           Mike      NaN      NaN  4500   NaN    NaN      NaN    35   NaN\n",
        "```\n"
      ],
      "metadata": {
        "id": "ShzJ65AwGv6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarize the API documentation using context\n",
        "(in this case, then entire documentation for the \"pandas\" website was pasted in as the prompt)"
      ],
      "metadata": {
        "id": "PCgj_DL5LD1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure that 'prompt_context' is set to True (defaults to True)\n",
        "summarize_apis = gpt.GPTService(role_context='api_explain',\n",
        "                            temperature=0,\n",
        "                            prompt_context=True,\n",
        "                            md_table_format_style='pipes')"
      ],
      "metadata": {
        "id": "Q4JEgC1yIWYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize_apis.prompt = \"\"\"\n",
        "DataFrame.merge(right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=None, indicator=False, validate=None)\n",
        "Merge DataFrame or named Series objects with a database-style join.\n",
        "\n",
        "A named Series object is treated as a DataFrame with a single named column.\n",
        "\n",
        "The join is done on columns or indexes. If joining columns on columns, the DataFrame indexes will be ignored. Otherwise if joining indexes on indexes or indexes on a column or columns, the index will be passed on. When performing a cross merge, no column specifications to merge on are allowed.\n",
        "\n",
        "Parameters:\n",
        "rightDataFrame or named Series\n",
        "Object to merge with.\n",
        "\n",
        "how{‘left’, ‘right’, ‘outer’, ‘inner’, ‘cross’}, default ‘inner’\n",
        "Type of merge to be performed.\n",
        "\n",
        "left: use only keys from left frame, similar to a SQL left outer join; preserve key order.\n",
        "\n",
        "right: use only keys from right frame, similar to a SQL right outer join; preserve key order.\n",
        "\n",
        "outer: use union of keys from both frames, similar to a SQL full outer join; sort keys lexicographically.\n",
        "\n",
        "inner: use intersection of keys from both frames, similar to a SQL inner join; preserve the order of the left keys.\n",
        "\n",
        "cross: creates the cartesian product from both frames, preserves the order of the left keys.\n",
        "\n",
        "\n",
        "onlabel or list\n",
        "Column or index level names to join on. These must be found in both DataFrames. If on is None and not merging on indexes then this defaults to the intersection of the columns in both DataFrames.\n",
        "\n",
        "left_onlabel or list, or array-like\n",
        "Column or index level names to join on in the left DataFrame. Can also be an array or list of arrays of the length of the left DataFrame. These arrays are treated as if they are columns.\n",
        "\n",
        "right_onlabel or list, or array-like\n",
        "Column or index level names to join on in the right DataFrame. Can also be an array or list of arrays of the length of the right DataFrame. These arrays are treated as if they are columns.\n",
        "\n",
        "left_indexbool, default False\n",
        "Use the index from the left DataFrame as the join key(s). If it is a MultiIndex, the number of keys in the other DataFrame (either the index or a number of columns) must match the number of levels.\n",
        "\n",
        "right_indexbool, default False\n",
        "Use the index from the right DataFrame as the join key. Same caveats as left_index.\n",
        "\n",
        "sortbool, default False\n",
        "Sort the join keys lexicographically in the result DataFrame. If False, the order of the join keys depends on the join type (how keyword).\n",
        "\n",
        "suffixeslist-like, default is (“_x”, “_y”)\n",
        "A length-2 sequence where each element is optionally a string indicating the suffix to add to overlapping column names in left and right respectively. Pass a value of None instead of a string to indicate that the column name from left or right should be left as-is, with no suffix. At least one of the values must not be None.\n",
        "\n",
        "copybool, default True\n",
        "If False, avoid copy if possible.\n",
        "\n",
        "indicatorbool or str, default False\n",
        "If True, adds a column to the output DataFrame called “_merge” with information on the source of each row. The column can be given a different name by providing a string argument. The column will have a Categorical type with the value of “left_only” for observations whose merge key only appears in the left DataFrame, “right_only” for observations whose merge key only appears in the right DataFrame, and “both” if the observation’s merge key is found in both DataFrames.\n",
        "\n",
        "validatestr, optional\n",
        "If specified, checks if merge is of specified type.\n",
        "\n",
        "“one_to_one” or “1:1”: check if merge keys are unique in both left and right datasets.\n",
        "\n",
        "“one_to_many” or “1:m”: check if merge keys are unique in left dataset.\n",
        "\n",
        "“many_to_one” or “m:1”: check if merge keys are unique in right dataset.\n",
        "\n",
        "“many_to_many” or “m:m”: allowed, but does not result in checks.\n",
        "\n",
        "Returns:\n",
        "DataFrame\n",
        "A DataFrame of the two merged objects.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "N1_LqtYQIab1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize_apis.get_response(summarize_apis.prompt)"
      ],
      "metadata": {
        "id": "DOgMgFc5I6ED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataFrame.merge\n",
        "\n",
        "Merge DataFrame or named Series objects with a database-style join.\n",
        "\n",
        "A named Series object is treated as a DataFrame with a single named column.\n",
        "\n",
        "The join is done on columns or indexes. If joining columns on columns, the DataFrame indexes will be ignored. Otherwise if joining indexes on indexes or indexes on a column or columns, the index will be passed on. When performing a cross merge, no column specifications to merge on are allowed.\n",
        "\n",
        "## Parameters\n",
        "\n",
        "| Parameter | Description |\n",
        "| --- | --- |\n",
        "| right | DataFrame or named Series. Object to merge with. |\n",
        "| how | {'left', 'right', 'outer', 'inner', 'cross'}, default 'inner'. Type of merge to be performed. |\n",
        "| on | label or list. Column or index level names to join on. These must be found in both DataFrames. If on is None and not merging on indexes then this defaults to the intersection of the columns in both DataFrames. |\n",
        "| left_on | label or list, or array-like. Column or index level names to join on in the left DataFrame. Can also be an array or list of arrays of the length of the left DataFrame. These arrays are treated as if they are columns. |\n",
        "| right_on | label or list, or array-like. Column or index level names to join on in the right DataFrame. Can also be an array or list of arrays of the length of the right DataFrame. These arrays are treated as if they are columns. |\n",
        "| left_index | bool, default False. Use the index from the left DataFrame as the join key(s). If it is a MultiIndex, the number of keys in the other DataFrame (either the index or a number of columns) must match the number of levels. |\n",
        "| right_index | bool, default False. Use the index from the right DataFrame as the join key. Same caveats as left_index. |\n",
        "| sort | bool, default False. Sort the join keys lexicographically in the result DataFrame. If False, the order of the join keys depends on the join type (how keyword). |\n",
        "| suffixes | list-like, default is (\"_x\", \"_y\"). A length-2 sequence where each element is optionally a string indicating the suffix to add to overlapping column names in left and right respectively. Pass a value of None instead of a string to indicate that the column name from left or right should be left as-is, with no suffix. At least one of the values must not be None. |\n",
        "| copy | bool, default True. If False, avoid copy if possible. |\n",
        "| indicator | bool or str, default False. If True, adds a column to the output DataFrame called \"_merge\" with information on the source of each row. The column can be given a different name by providing a string argument. The column will have a Categorical type with the value of \"left_only\" for observations whose merge key only appears in the left DataFrame, \"right_only\" for observations whose merge key only appears in the right DataFrame, and \"both\" if the observation's merge key is found in both DataFrames. |\n",
        "| validate | str, optional. If specified, checks if merge is of specified type. \"one_to_one\" or \"1:1\": check if merge keys are unique in both left and right datasets. \"one_to_many\" or \"1:m\": check if merge keys are unique in left dataset. \"many_to_one\" or \"m:1\": check if merge keys are unique in right dataset. \"many_to_many\" or \"m:m\": allowed, but does not result in checks. |\n",
        "\n",
        "## Returns\n",
        "\n",
        "DataFrame: A DataFrame of the two merged objects.\n",
        "\n",
        "---\n",
        "\n",
        "### Example 1\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "df1 = pd.DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'c']})\n",
        "df2 = pd.DataFrame({'A': [1, 2, 4], 'C': ['x', 'y', 'z']})\n",
        "\n",
        "merged_df = df1.merge(df2, on='A')\n",
        "\n",
        "print(merged_df)\n",
        "```\n",
        "\n",
        "Output:\n",
        "```\n",
        "   A  B  C\n",
        "0  1  a  x\n",
        "1  2  b  y\n",
        "```\n",
        "\n",
        "In this example, two DataFrames `df1` and `df2` are merged on the column 'A'. The resulting merged DataFrame contains the common rows from both DataFrames.\n",
        "\n",
        "---\n",
        "\n",
        "### Example 2\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "df1 = pd.DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'c']})\n",
        "df2 = pd.DataFrame({'A': [1, 2, 4], 'C': ['x', 'y', 'z']})\n",
        "\n",
        "merged_df = df1.merge(df2, how='outer')\n",
        "\n",
        "print(merged_df)\n",
        "```\n",
        "\n",
        "Output:\n",
        "```\n",
        "   A    B    C\n",
        "0  1    a    x\n",
        "1  2    b    y\n",
        "2  3    c  NaN\n",
        "3  4  NaN    z\n",
        "```\n",
        "\n",
        "In this example, two DataFrames `df1` and `df2` are merged using the 'outer' join type. The resulting merged DataFrame contains all rows from both DataFrames, with missing values (NaN) filled in for non-matching rows.\n",
        "\n",
        "---\n",
        "\n",
        "### Example 3\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "df1 = pd.DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'c']})\n",
        "df2 = pd.DataFrame({'A': [1, 2, 4], 'C': ['x', 'y', 'z']})\n",
        "\n",
        "merged_df = df1.merge(df2, left_on='A', right_on='A', suffixes=('_left', '_right'))\n",
        "\n",
        "print(merged_df)\n",
        "```\n",
        "\n",
        "Output:\n",
        "```\n",
        "   A B_left C_right\n",
        "0  1      a       x\n",
        "1  2      b       y\n",
        "```"
      ],
      "metadata": {
        "id": "OXSd8hi-J6eJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0XyWoLRnEu6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Help with specific coding questions"
      ],
      "metadata": {
        "id": "asiTBAs9LcLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the class using the 'code_help' string\n",
        "# setting the context for the state that ensures resultant responses\n",
        "# are pertinent to coding related questions.\n",
        "# In this scenario we will leave all other params as default\n",
        "code_help = gpt.GPTService(role_context='code_help')"
      ],
      "metadata": {
        "id": "7VdkSqwuLfFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code_help.prompt = \"using a lambda function with the pandas .agg method?\""
      ],
      "metadata": {
        "id": "MR7esZWKL-W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code_help.get_response(code_help.prompt)"
      ],
      "metadata": {
        "id": "LEehT_8nMAGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The lambda function is a concise way to define anonymous functions in Python.\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "When used with the `.agg` method in pandas, it allows you to apply custom aggregations to your data. Here are two examples:\n",
        "\n",
        "Example 1: Calculating the sum and mean of a column\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame\n",
        "data = {'A': [1, 2, 3, 4, 5],\n",
        "        'B': [6, 7, 8, 9, 10]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Use .agg with lambda to calculate sum and mean\n",
        "result = df['A'].agg(lambda x: (x.sum(), x.mean()))\n",
        "print(result)\n",
        "```\n",
        "Output:\n",
        "```\n",
        "(15, 3.0)\n",
        "```\n",
        "In this example, the lambda function takes the column `A` as input (`x`) and returns a tuple containing the sum and mean of the column.\n",
        "\n",
        "Example 2: Applying multiple aggregations to different columns\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame\n",
        "data = {'A': [1, 2, 3, 4, 5],\n",
        "        'B': [6, 7, 8, 9, 10]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Use .agg with lambda to calculate sum for column A and mean for column B\n",
        "result = df.agg({'A': lambda x: x.sum(), 'B': lambda x: x.mean()})\n",
        "print(result)\n",
        "```\n",
        "Output:\n",
        "```\n",
        "A     15.0\n",
        "B      8.0\n",
        "dtype: float64\n",
        "```\n",
        "In this example, the lambda functions are used to define different aggregations for columns `A` and `B`.\n",
        "\n",
        "And now, for a coding joke:\n",
        "\n",
        "Why do programmers prefer dark mode?\n",
        "\n",
        "Because light attracts bugs!"
      ],
      "metadata": {
        "id": "u7eZYYxdMFnX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code help #2"
      ],
      "metadata": {
        "id": "iLBkzL3RM8l7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "code_help.prompt = \"how get subset of dataframe where 'profit' column values are greater than 50% of the average\"\n",
        "code_help.get_response(code_help.prompt)"
      ],
      "metadata": {
        "id": "s1S890yiMIsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get a subset of a dataframe where the 'profit' column values are greater than 50% of the average, you can use the following code:\n",
        "\n",
        "```python\n",
        "subset_df = df[df['profit'] > df['profit'].mean() * 0.5]\n",
        "```\n",
        "\n",
        "This code filters the dataframe `df` based on the condition where the 'profit' column values are greater than 50% of the average profit.\n",
        "\n",
        "Here are two examples:\n",
        "\n",
        "Example 1:\n",
        "```python\n",
        "subset_df = df[df['profit'] > df['profit'].mean() * 0.5]\n",
        "print(subset_df)\n",
        "```\n",
        "\n",
        "Example 2:\n",
        "```python\n",
        "subset_df = df[df['profit'] > df['profit'].mean() * 0.5]\n",
        "subset_df.to_csv('subset.csv', index=False)\n",
        "```\n",
        "\n",
        "And now, for a coding joke:\n",
        "\n",
        "Why do programmers prefer dark mode?\n",
        "\n",
        "Because light attracts bugs!"
      ],
      "metadata": {
        "id": "l4g3zB1JNUZO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PFxpXmOKNRCF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}